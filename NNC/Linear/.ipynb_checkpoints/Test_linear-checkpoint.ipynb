{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca128654-a476-4faf-8240-3dfc2e7aefaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "import control\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchsde\n",
    "from torch import nn, profiler, Tensor, nan, vmap\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../..')) \n",
    "sys.path.append(project_root)  # Add folder_a to sys.path\n",
    "sys.path.append(os.path.join(project_root, '../..', 'Networks'))  # Add folder_b to sys.path\n",
    "\n",
    "from Networks.utils import get_gpu_memory, normal, ema_update,mass_append, update_ema, generate_system_canon, load_clean_state_dict, sample_linear, compute_gradnorm,save_model, loss_compute\n",
    "from helpers import   HyperCoeffsLinearControlStochasticLQRImpl,  find_params\n",
    "import psutil\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from adabelief_pytorch import AdaBelief\n",
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if is_cuda else 'cpu'\n",
    "\n",
    "if not is_cuda:\n",
    "    print(\"Warning: CUDA not available; falling back to CPU but this is likely to be very slow.\")\n",
    "import gc\n",
    "path=os.path.abspath(os.getcwd())\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c757c69d-604f-47f3-a08d-9c86ff73ae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#state size\n",
    "state_size=128\n",
    "#batch size\n",
    "batch_size=1024\n",
    "#weight\n",
    "weight=0.1\n",
    "#initialize canonical A and B\n",
    "A,B=generate_system_canon(state_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa63f6d-8ffa-426b-81f1-15d268ff2442",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()            \n",
    "\n",
    "global_means=[]\n",
    "global_stds=[]\n",
    "At=torch.tensor(A).float().to(device) \n",
    "Bt=torch.tensor(B).float().to(device) \n",
    "coremat=(At.unsqueeze(0)).repeat(batch_size,1,1)\n",
    "\n",
    "t_total=1\n",
    "t_size=int(32)\n",
    "ts_exp = torch.linspace(0, t_total, t_size).float().to(device)\n",
    "iter = 2500\n",
    "\n",
    "for layers in range(1,5):\n",
    "    #choose strategy\n",
    "    strategy=\"HNC\"\n",
    "    #initialize model\n",
    "    SMLt= HyperCoeffsLinearControlStochasticLQRImpl(At,Bt,batch_size, device,layers,strategy).to(device) \n",
    "    load_clean_state_dict(SMLt,  path+\"/\" + strategy + \"ema\" + str(layers)+ \".pth\")\n",
    "    \n",
    "    seed=0\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    count=0\n",
    "    mean=0\n",
    "    M2=0\n",
    "    for j in tqdm(range(0,iter)):\n",
    "\n",
    "        amat, x0= sample_linear(dim,batch_size, device)   \n",
    "        \n",
    "        ini_enr = torch.zeros(batch_size, 1).to(device)\n",
    "        ys_exp = torch.cat((x0,ini_enr),dim=1).to(device)\n",
    "        \n",
    "        coremat[:,-1,:]=amat\n",
    "        SMLt.At= coremat\n",
    "        SMLt.poly.amat=amat\n",
    "\n",
    "        with torch.no_grad():\n",
    "            ys_tray = torchsde.sdeint_adjoint(SMLt, ys_exp, ts_exp,method='reversible_heun', dt=ts_exp[1]-ts_exp[0],\n",
    "                                 adjoint_method='adjoint_reversible_heun',)\n",
    "            \n",
    "\n",
    "        print(psutil.virtual_memory())\n",
    "        dif=torch.sum(ys_tray[-1,:,0:dim]**2,dim=1)\n",
    "        dif1=weight*ys_tray[-1,:,-1]   \n",
    "        diff=dif+dif1\n",
    "\n",
    "        batch=diff.detach().cpu().numpy()\n",
    "        b_count=batch.size\n",
    "        b_mean=batch.mean()\n",
    "        b_M2 = ((batch - b_mean) ** 2).sum()\n",
    "        delta = b_mean - mean\n",
    "        total = count + b_count    \n",
    "        mean += delta * b_count / total\n",
    "        M2 += b_M2 + delta**2 * count * b_count / total    \n",
    "        count = total\n",
    "       \n",
    "        print(\"current ste\")\n",
    "        print(np.sqrt(M2/ (count-1))/np.sqrt(count))\n",
    "        print(\"current mean\")\n",
    "        print(mean)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        del ys_tray,x0\n",
    "    variance = M2/ (count-1)\n",
    "    ste= np.sqrt(variance)/np.sqrt(count)\n",
    "   \n",
    "    global_means.append(mean)\n",
    "    global_stds.append(ste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cda5695-31ed-475f-bd76-d832eed6735e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
